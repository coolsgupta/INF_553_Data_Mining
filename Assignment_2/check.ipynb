{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_itemset_counts(basket):\n",
    "    if set_size > 1:\n",
    "        sets = itertools.combinations(basket[1], set_size)\n",
    "\n",
    "    else:\n",
    "        sets = basket[1]\n",
    "\n",
    "    return list(map(lambda x: (x, 1), sets))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_itemset_candidates(bucket):\n",
    "    items = {}\n",
    "    for basket in bucket:\n",
    "        if len(basket[1]) < set_size:\n",
    "            continue\n",
    "\n",
    "        if set_size > 1:\n",
    "            sets = itertools.combinations(basket[1], set_size)\n",
    "\n",
    "        else:\n",
    "            sets = basket[1]\n",
    "\n",
    "        for item in sets:\n",
    "            if item not in items:\n",
    "                items[item] = 0\n",
    "\n",
    "            items[item] += 1\n",
    "\n",
    "    print(items)\n",
    "    for item in items:\n",
    "        if items[item] >= partial_support:\n",
    "            yield item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates_list(candidate_baskets):\n",
    "    candidate_sets = candidate_baskets.mapPartitions(get_partition_itemset_candidates)\n",
    "    candidate_sets_list = candidate_sets.distinct().collect()\n",
    "    return candidate_sets_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_frequent_sets(original_baskets, candidate_list):\n",
    "    original_freq_sets = original_baskets \\\n",
    "        .flatMap(get_original_itemset_counts) \\\n",
    "        .filter(lambda x: x[0] in candidate_list) \\\n",
    "        .reduceByKey(lambda a, b: a + b) \\\n",
    "        .filter(lambda x: x[1] >= support)\\\n",
    "        .map(lambda x: (x[0]))\\\n",
    "        .collect()\n",
    "\n",
    "    return original_freq_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_candidates, result_frequent_itemsets):\n",
    "    with open('jupyter_test_results', 'w') as results_file:\n",
    "        results_file.write('Candidates:\\n')\n",
    "        output = ''\n",
    "        for single_cad in sorted(result_candidates[0]):\n",
    "            output += '(' + str(single_cad) + '),'\n",
    "\n",
    "        results_file.write(output[-1])\n",
    "\n",
    "        for cand_set in result_candidates[1:]:\n",
    "            results_file.write(str(sorted(cand_set))[1:-1] + '\\n\\n')\n",
    "\n",
    "        results_file.write('Frequent Itemsets:\\n')\n",
    "        output = ''\n",
    "        for single_item in sorted(result_frequent_itemsets[0]):\n",
    "            output += '(' + str(single_item) + '),'\n",
    "\n",
    "        results_file.write(output[-1])\n",
    "\n",
    "        for freq_set in result_frequent_itemsets[1:]:\n",
    "\n",
    "            results_file.write(str(sorted(freq_set))[1:-1] + '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', ['100', '101', '102', '98']), ('4', ['101', '102', '103', '97', '99']), ('8', ['102', '103', '104', '97', '98', '99']), ('9', ['97', '98', '99']), ('10', ['97', '98']), ('12', ['100', '101', '102', '105', '106', '107', '108', '98']), ('16', ['100', '101', '98', '99']), ('19', ['102', '97', '98']), ('14', ['97']), ('17', ['97', '99']), ('2', ['100', '101', '97', '99']), ('3', ['102', '103', '105', '97', '98', '99']), ('5', ['97', '98']), ('6', ['101', '102']), ('7', ['101', '97', '99']), ('11', ['97', '98', '99']), ('13', ['100', '101', '102', '103', '105', '106', '107', '108', '98', '99']), ('15', ['101', '97', '99']), ('18', ['97', '98', '99'])]\n"
     ]
    }
   ],
   "source": [
    "case = '1'\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"4g\")\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "conf.setMaster('local[8]')\n",
    "conf.setAppName('Assignment_2')\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "\n",
    "data_path = 'asnlib/publicdata/'\n",
    "\n",
    "data = sc.textFile(data_path + 'small1.csv').map(lambda x: x.split(',')).map(lambda x: (x[0], x[1]))\n",
    "header = data.first()\n",
    "raw_data = data.filter(lambda x: x != header)\n",
    "\n",
    "\n",
    "if case == '2':\n",
    "    raw_data = raw_data.map(lambda x: (x[1], x[0]))\n",
    "\n",
    "baskets = raw_data.distinct().groupByKey().map(lambda x: (x[0], sorted(list(x[1]))))\n",
    "print(baskets.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 4\n",
    "partial_support = support // baskets.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "frequent_itemsets = []\n",
    "set_size = 1\n",
    "while True:\n",
    "    current_candidates = get_candidates_list(candidate_baskets=baskets)\n",
    "    # current_candidates = []\n",
    "    current_frequent_itemsets = get_original_frequent_sets(\n",
    "        original_baskets=baskets,\n",
    "        candidate_list=current_candidates\n",
    "    )\n",
    "    if not current_candidates:\n",
    "        break\n",
    "    candidates.append(current_candidates)\n",
    "    if current_frequent_itemsets:\n",
    "        frequent_itemsets.append(current_frequent_itemsets)\n",
    "    set_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_candidates, result_frequent_itemsets):\n",
    "    with open('jupyter_test_results', 'w') as results_file:\n",
    "        results_file.write('Candidates:\\n')\n",
    "        output = ''\n",
    "        for single_cad in sorted(result_candidates[0]):\n",
    "            output += '(' + str(single_cad) + '),'\n",
    "\n",
    "        results_file.write(output[-1])\n",
    "\n",
    "        for cand_set in result_candidates[1:]:\n",
    "            results_file.write(str(sorted(cand_set))[1:-1] + '\\n\\n')\n",
    "\n",
    "        results_file.write('Frequent Itemsets:\\n')\n",
    "        output = ''\n",
    "        for single_item in sorted(result_frequent_itemsets[0]):\n",
    "            output += '(' + str(single_item) + '),'\n",
    "\n",
    "        results_file.write(output[-1])\n",
    "\n",
    "        for freq_set in result_frequent_itemsets[1:]:\n",
    "\n",
    "            results_file.write(str(sorted(freq_set))[1:-1] + '\\n\\n')\n",
    "\n",
    "write_results(result_candidates=candidates, result_frequent_itemsets=frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for single_cad in sorted(candidates[0]):\n",
    "    text += '(\\'' + str(single_cad) + '\\'),'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('100'),('101'),('102'),('103'),('105'),('97'),('98'),('99'),\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['100', '102', '98', '101', '103', '97', '99', '105'],\n",
       " [('100', '102'),\n",
       "  ('100', '98'),\n",
       "  ('102', '98'),\n",
       "  ('101', '99'),\n",
       "  ('103', '97'),\n",
       "  ('103', '99'),\n",
       "  ('97', '99'),\n",
       "  ('101', '97'),\n",
       "  ('103', '105'),\n",
       "  ('105', '99'),\n",
       "  ('100', '101'),\n",
       "  ('101', '102'),\n",
       "  ('101', '98'),\n",
       "  ('102', '103'),\n",
       "  ('102', '97'),\n",
       "  ('102', '99'),\n",
       "  ('97', '98'),\n",
       "  ('98', '99'),\n",
       "  ('100', '99'),\n",
       "  ('102', '105'),\n",
       "  ('103', '98'),\n",
       "  ('105', '98')],\n",
       " [('100', '101', '102'),\n",
       "  ('100', '101', '98'),\n",
       "  ('101', '102', '98'),\n",
       "  ('103', '97', '99'),\n",
       "  ('102', '97', '98'),\n",
       "  ('101', '97', '99'),\n",
       "  ('102', '103', '98'),\n",
       "  ('102', '105', '98'),\n",
       "  ('102', '98', '99'),\n",
       "  ('103', '105', '99'),\n",
       "  ('100', '102', '98'),\n",
       "  ('102', '103', '97'),\n",
       "  ('102', '103', '99'),\n",
       "  ('102', '97', '99'),\n",
       "  ('97', '98', '99'),\n",
       "  ('100', '101', '99'),\n",
       "  ('102', '103', '105'),\n",
       "  ('102', '105', '99'),\n",
       "  ('103', '105', '98'),\n",
       "  ('103', '98', '99'),\n",
       "  ('105', '98', '99')],\n",
       " [('102', '103', '105', '98'),\n",
       "  ('102', '103', '98', '99'),\n",
       "  ('102', '105', '98', '99'),\n",
       "  ('100', '101', '102', '98'),\n",
       "  ('102', '103', '97', '99'),\n",
       "  ('102', '103', '105', '99'),\n",
       "  ('103', '105', '98', '99')],\n",
       " [('102', '103', '105', '98', '99')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['100', '102', '98', '101', '103', '97', '99'],\n",
       " [('100', '98'),\n",
       "  ('102', '98'),\n",
       "  ('101', '97'),\n",
       "  ('101', '99'),\n",
       "  ('103', '99'),\n",
       "  ('97', '99'),\n",
       "  ('100', '101'),\n",
       "  ('101', '102'),\n",
       "  ('101', '98'),\n",
       "  ('102', '103'),\n",
       "  ('102', '97'),\n",
       "  ('102', '99'),\n",
       "  ('97', '98'),\n",
       "  ('98', '99')],\n",
       " [('100', '101', '98'),\n",
       "  ('101', '97', '99'),\n",
       "  ('102', '103', '99'),\n",
       "  ('97', '98', '99')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

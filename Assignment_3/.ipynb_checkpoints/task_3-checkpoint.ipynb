{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import json\n",
    "import itertools\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_min_hash_func(a, b, p, m):\n",
    "    def min_hash_func(x):\n",
    "        return (((a * x + b) % p) % m)\n",
    "\n",
    "    return min_hash_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_hash_functions(num_func, buckets):\n",
    "    list_a = random.sample(range(50331653, 92233720), num_func)\n",
    "    list_b = random.sample(range(25165843, 92233720), num_func)\n",
    "    p = 12582917\n",
    "    min_hash_func_list = [build_min_hash_func(a, b, p, buckets) for a, b in zip(list_a, list_b)]\n",
    "\n",
    "    return min_hash_func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_jaccard_similarity(candidate, business_user_tokens):\n",
    "    business_set_1 = set(business_user_tokens.get(candidate[0], []))\n",
    "    business_set_2 = set(business_user_tokens.get(candidate[1], []))\n",
    "    pair_jac_sim = 0\n",
    "    if business_set_1 and business_set_2:\n",
    "        pair_jac_sim = len(business_set_1.intersection(business_set_2)) / len(business_set_1.union(business_set_2))\n",
    "    return tuple([candidate, pair_jac_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(results, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in results:\n",
    "            file.write(json.dumps(line) + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimilarity(dict1, dict2):\n",
    "    \"\"\"\n",
    "    compute Pearson Correlation Similarity\n",
    "    :param dict1:\n",
    "    :param dict2:\n",
    "    :return: a float number\n",
    "    \"\"\"\n",
    "    co_rated_user = list(set(dict1.keys()) & (set(dict2.keys())))\n",
    "    val1_list, val2_list = list(), list()\n",
    "    [(val1_list.append(dict1[user_id]),\n",
    "      val2_list.append(dict2[user_id])) for user_id in co_rated_user]\n",
    "\n",
    "    avg1 = sum(val1_list) / len(val1_list)\n",
    "    avg2 = sum(val2_list) / len(val2_list)\n",
    "\n",
    "    numerator = sum(map(lambda pair: (pair[0] - avg1) * (pair[1] - avg2), zip(val1_list, val2_list)))\n",
    "\n",
    "    if numerator == 0:\n",
    "        return 0\n",
    "    denominator = math.sqrt(sum(map(lambda val: (val - avg1) ** 2, val1_list))) * \\\n",
    "                  math.sqrt(sum(map(lambda val: (val - avg2) ** 2, val2_list)))\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"4g\")\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "conf.setMaster('local[8]')\n",
    "conf.setAppName('Assignment_3')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_json = sc.textFile(\"asnlib/publicdata/train_review.json\").map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'pxOrtki0sqXps5hSyLXKpA',\n",
       " 'user_id': 'OLR4DvqFxCKLOEHqfAxpqQ',\n",
       " 'business_id': 'zK7sltLeRRioqYwgLiWUIA',\n",
       " 'stars': 5.0,\n",
       " 'text': \"Second time I've been here. First time was whatever. This time it was actually good. Way better than inn n out. It's the same type of burger that's why I put it up against that. I love that you can get grilled jalapeÃ±os. Just wish they came on the burger and not on the side.\",\n",
       " 'date': '2015-12-19 07:35:30'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_json.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_rating_sets = reviews_json.map(lambda x: (x.get('user_id'), x.get('business_id'), x.get('stars'))).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user tokens\n",
    "user_tokens_dict = user_business_rating_sets\\\n",
    "    .map(lambda x: x[0])\\\n",
    "    .distinct()\\\n",
    "    .sortBy(lambda x: x)\\\n",
    "    .zipWithIndex()\\\n",
    "    .collectAsMap()\n",
    "\n",
    "inverse_user_tokens_dict = {bid: token for token, bid in user_tokens_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create business tokens\n",
    "business_tokens = user_business_rating_sets\\\n",
    "    .map(lambda x: x[1])\\\n",
    "    .distinct()\\\n",
    "    .sortBy(lambda x: x)\\\n",
    "    .zipWithIndex()\\\n",
    "    \n",
    "business_tokens_dict = business_tokens.collectAsMap()\n",
    "\n",
    "inverse_business_tokens_dict = {bid: token for token, bid in business_tokens_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hash_func_list = get_min_hash_functions(50, len(user_tokens_dict) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user business tokenized maps\n",
    "user_business_rating_tokenized_sets = user_business_rating_sets\\\n",
    "    .map(lambda x: (user_tokens_dict.get(x[0]), business_tokens_dict.get(x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_user_tokenized_pairs = user_business_rating_tokenized_sets.map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create business user list\n",
    "business_user_tokenized_map = business_user_tokenized_pairs.groupByKey().mapValues(lambda x: list(set(x))).filter(lambda x: len(x[1])>=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10118"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_user_tokenized_map.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_tokenized_dict = business_user_tokenized_map.flatMap(lambda x: [(user, x[0]) for user in x[1]]).groupByKey().mapValues(lambda x: list(set(x))).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_hashed_values = business_tokens.map(lambda x: (x[1], [min_hash(x[1]) for min_hash in min_hash_func_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix_rdd = business_user_tokenized_map\\\n",
    "    .leftOuterJoin(business_hashed_values)\\\n",
    "    .map(lambda x: x[1])\\\n",
    "    .flatMap(lambda user_set: [(x, user_set[1]) for x in user_set[0]])\\\n",
    "    .reduceByKey(lambda a, b: [min(x, y) for x, y in zip(a, b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23632,\n",
       " [3570,\n",
       "  3392,\n",
       "  5657,\n",
       "  352,\n",
       "  2278,\n",
       "  5971,\n",
       "  1378,\n",
       "  571,\n",
       "  792,\n",
       "  3048,\n",
       "  3444,\n",
       "  300,\n",
       "  4868,\n",
       "  30,\n",
       "  1860,\n",
       "  950,\n",
       "  2580,\n",
       "  509,\n",
       "  2928,\n",
       "  2345,\n",
       "  2715,\n",
       "  3283,\n",
       "  467,\n",
       "  3647,\n",
       "  1537,\n",
       "  771,\n",
       "  200,\n",
       "  2102,\n",
       "  748,\n",
       "  2001,\n",
       "  5,\n",
       "  758,\n",
       "  2358,\n",
       "  2907,\n",
       "  1591,\n",
       "  4395,\n",
       "  26,\n",
       "  1769,\n",
       "  717,\n",
       "  6972,\n",
       "  20,\n",
       "  525,\n",
       "  412,\n",
       "  552,\n",
       "  1595,\n",
       "  2473,\n",
       "  656,\n",
       "  2166,\n",
       "  7949,\n",
       "  6723])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_matrix_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = signature_matrix_rdd \\\n",
    "    .flatMap(lambda x: [(tuple([i, tuple(x[1][i:i + 1])]), x[0]) for i in range(0, 50)]) \\\n",
    "    .groupByKey()\\\n",
    "    .map(lambda x: list(x[1]))\\\n",
    "    .filter(lambda val: len(val) > 1) \\\n",
    "    .flatMap(lambda uid_list: [pair for pair in itertools.combinations(uid_list, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48495849"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similar_users = candidate_pairs\\\n",
    "        .distinct()\\\n",
    "        .map(lambda x: check_jaccard_similarity(x, user_business_tokenized_dict))\\\n",
    "        .filter(lambda x: x[1] >= 0.01)\\\n",
    "#         .map(lambda x: {\"b1\": inverse_business_tokens_dict[x[0][0]], \"b2\": inverse_business_tokens_dict[x[0][1]], \"sim\": x[1]})\\\n",
    "#         .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23632, 24958), 0.03225806451612903)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similar_users.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21491909"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similar_users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_rating_map = user_business_rating_tokenized_sets.map(lambda x: (x[0], (x[1], x[2]))).groupByKey().mapValues(lambda x: list(set(x))).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26184"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_business_rating_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_similar_pairs = jaccard_similar_users.map(lambda id_pair: (id_pair, computeSimilarity(user_business_rating_map[id_pair[0]], user_business_rating_map[id_pair[1]]))).filter(lambda kv: kv[1] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_similar_pairs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
